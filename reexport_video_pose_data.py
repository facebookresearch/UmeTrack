"""
Convert the nimble internal format (generated by this notebook: N3032236)
into the release reaady format
"""
import fnmatch
import json
import os
from multiprocessing import Pool

import lib.data_utils.fs as fs


def _find_input_output_files(input_dir: str, output_dir: str):
    res_input_paths = []
    res_output_paths = []
    for cur_dir, _, filenames in fs.walk(input_dir):
        mp4_files = fnmatch.filter(filenames, "*.mp4")
        input_full_paths = [fs.join(cur_dir, fname) for fname in mp4_files]
        rel_paths = [f[len(input_dir):] for f in input_full_paths]
        output_full_paths = [fs.join(output_dir, f[:-4] + ".mp4") for f in rel_paths]
        res_input_paths += input_full_paths
        res_output_paths += output_full_paths
    assert len(res_input_paths) == len(res_output_paths)
    print(f"Found {len(res_input_paths)} files from {input_dir}")
    return res_input_paths, res_output_paths


def _reexport_file(input_output):
    input_file, output_file = input_output
    if not fs.exists(fs.dirname(output_file)):
        os.makedirs(fs.dirname(output_file))

    # shutil.copy(input_file, output_file)
    input_json_file = input_file[:-4] + ".json"
    output_json_file = output_file[:-4] + ".json"
    with fs.open(input_json_file, "rb") as fp:
        output_dict = json.load(fp)

    output_dict["wrist_transforms"] = output_dict.pop("wrist_transforms_world")
    output_dict["camera_to_world_transforms"] = output_dict.pop("camera_extrinsics")

    for camera in output_dict["cameras"]:
        # We don't need the static world to eye matrix
        camera.pop("ModelViewMatrix")
        camera["DistortionModel"] = "FishEye62"

    with fs.open(output_json_file, "wb") as f_json:
        f_json.write(json.dumps(output_dict, indent=4).encode("utf-8"))

if __name__ == '__main__':
    root = os.path.dirname(os.path.dirname(__file__))
    input_paths, output_paths = _find_input_output_files(
        os.path.join(root, "raw_data_orig"),
        os.path.join(root, "raw_data"),
    )
    n_processed = 0
    # for p_in, p_out in zip(input_paths, output_paths):
    #     _reexport_file(p_in, p_out)
    #     n_processed += 1
    #     if n_processed % 20 == 0:
    #         print(f"Processed {n_processed} out of {len(input_paths)} files")
    pool_size = 16
    with Pool(pool_size) as p:
        p.map_async(_reexport_file, zip(input_paths, output_paths)).get()
